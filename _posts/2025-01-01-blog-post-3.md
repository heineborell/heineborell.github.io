---
title: "Grand Tours Data Analysis-3 (File Structure)"
date: 2025-01-01
permalink: /posts/2025/01/blog-post-3/
tags:
  - tourde-france
  - cycling
  - data analysis
---

# Project Structure

The project is organized into multiple directories, each with a specific purpose. Below is an overview of the file tree and the functionalities of each file and directory.

## File Tree
<pre>
.
├── README.md
├── analysis
│   ├── activity_list_2024.py
│   ├── eda.ipynb
│   ├── eda.py
│   └── questions.md
├── data_tools
│   ├── data_cleaning
│   │   └── clean_tdf.py
│   └── sql_uploaders
│       ├── sql_json.py
│       ├── sql_results.py
│       ├── sql_strava_ids.py
│       └── sql_strava_names.py
├── pyproject.toml
├── scripts
│   ├── grand_tour
│   │   ├── letour_scraper.py
│   │   └── procycling_scraper.py
│   ├── locations
│   │   └── french_locations.py
│   └── strava
│       ├── activity_no_scr.py
│       ├── segment_scraper.py
│       └── strava_proid_scraper.py
└── src
    └── grand_tours
        ├── __init__.py
        ├── activity_scrape.py
        ├── chrome_driver.py
        ├── getters.py
        ├── logger_config.py
        ├── ride_scrape.py
        └── sql_upload.py
</pre>


---

## Directory Details

### **`analysis`**
Contains Python scripts and Jupyter notebooks for data analysis:
- `activity_list_2024.py`: Generates or processes a list of activities for 2024.
- `eda.ipynb` & `eda.py`: Exploratory Data Analysis (EDA) scripts.
- `questions.md`: Document with analysis-related questions or notes.

### **`data_tools`**
Holds tools for cleaning data and uploading it to a SQL database:
- **`data_cleaning/clean_tdf.py`**: Script for cleaning Tour de France data.
- **`sql_uploaders/`**: Scripts for uploading various data to SQL tables:
  - `sql_json.py`, `sql_results.py`, `sql_strava_ids.py`, `sql_strava_names.py`.

### **`scripts`**
Contains scrapers for gathering data from various sources:
- **`grand_tour/`**: Scripts for scraping race results:
  - `letour_scraper.py`: Scraper for [LeTour](https://www.letour.fr/en/). Note that I actually only
used ProCyclingStats data
  - `procycling_scraper.py`: Scraper for [ProCyclingStats](https://www.procyclingstats.com).
- **`locations/`**: Scraper for town coordinates from [Geokeo](https://geokeo.com):
  - `french_locations.py`: Scrapes coordinates for French towns.
- **`strava/`**: Scripts for scraping Strava data:
  - `strava_proid_scraper.py`: Scrapes Strava profile IDs which creates `strava_names` table.
  - `segment_scraper.py`: Scrapes Strava segment and stats data which creates `segments_data` and `stats_data`.
  - `activity_no_scr.py`: Scrapes activity IDs for specific riders and dates which I will talk about in detail later.

### **`src`**
Houses reusable modules for the project, adhering (to some extent) to the DRY principle:
- `activity_scrape.py`: Handles activity-related scraping.
- `chrome_driver.py`: Manages Chrome WebDriver configurations.
- `getters.py`: Utility functions for fetching data.
- `logger_config.py`: Logger configuration for debugging and tracking.
- `ride_scrape.py`: Handles specific ride-related scraping.
- `sql_upload.py`: Manages SQL data uploads.

---

## Development Approach

The project adheres to a modern Python project structure, utilizing `pyproject.toml` instead of older methods like `setup.py` and `requirements.txt`. This simplifies dependency management and project configuration.

### **`pyproject.toml`**
```toml
[build-system]
requires = ["setuptools", "setuptools-scm"]
build-backend = "setuptools.build_meta"

[project]
name = "grand_tours"
version = "0.1"
dependencies = [
    "selenium",
    "numpy",
    "pandas",
    "sqlalchemy",
    "pymysql",
    "mysqlclient"
]

[project.optional-dependencies]
dev = ["black", "flake8", "isort", "pre-commit"]
```
## Reflections 

"I aimed to be modular and stick to the DRY principle, but I believe I fell
short. Nevertheless, I learned a great deal from my mistakes. One reason the
code became messy was the nature of web scraping itself—data often contains
irregularities that require handling through exceptions and conditional
statements, which can complicate the structure. Moving forward, I hope to
approach similar tasks more professionally."





